# 🧠 Neural Network from Scratch (NumPy)

This project is a beginner-friendly neural network built **completely from scratch using NumPy**, without any deep learning libraries like TensorFlow or PyTorch.

It includes:
- Manual implementation of dense layers
- ReLU and softmax activation functions
- Categorical cross-entropy loss
- Modular files for better understanding of internal components

---

## 📁 Project Structure

neural_netwrok/

├── main.py # Full neural network pipeline with spiral dataset

├── softmax_fn.py # Independent softmax function example

├── loss_function.py # Independent categorical cross-entropy loss example

├── requirements.txt # Python packages required

└── README.md # Project documentation

---

## 📌 Key Features

- Built **entirely from scratch** with NumPy
- Feedforward neural network
- **ReLU activation** for hidden layers
- **Softmax activation** for output layer
- **Categorical Cross-Entropy Loss** calculation
- Uses a **spiral dataset** from `nnfs` for 3-class classification
- Educational modular structure for easier learning

---

## 🚀 Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/neural-net-from-scratch.git
cd neural_netwrok

### 2. Install Required Packages

Make sure Python 3.7+ is installed, then install the dependencies:

```bash
pip install -r requirements.txt

#### 🔹 How to run the project:

```markdown
### 3. Run the Files

Run the full neural network pipeline:

```bash
python main.py
