# neural_network
tion its a basic neural network i created from scratch for better understanding of how the neural network works . it consist of ReLU (Rectified Linear unit) Activation function , Softmax function and Loss function which are necessary for the working of a neural network . 
